{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "# from src.gaussian import Gaussian\n",
    "# from src.mix_gaussian import MixedGaussian\n",
    "from src.mi_estimators import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "torch.set_default_tensor_type(FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--rho\", type=float, default=0.9, help=\"coefficient of Gaussian\")\n",
    "parser.add_argument(\"--d\", type=int, default=16, help=\"dimension of X & Y\")\n",
    "parser.add_argument(\"--sample_size\", type=int, default=400, help=\"sample size\")\n",
    "parser.add_argument(\"--gamma\", type=float, default=1e-20, help=\"clipping parameter\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=100, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=100, help=\"Hidden dimension\")\n",
    "parser.add_argument(\"--ma_rate\", type=float, default=0.1, help=\"move average rate\")\n",
    "parser.add_argument(\"--ma_ef\", type=float, default=1, help=\"move average ef\")\n",
    "parser.add_argument(\"--alpha\", type=float, default=1e-4, help=\"smooth parameter\")\n",
    "\n",
    "parser.add_argument(\"--n_epoch\", type=int, default=2000, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--n_iters_1epoch\", type=int, default=4, help=\"number of epochs of training\")\n",
    "\n",
    "opt, unknown = parser.parse_known_args()\n",
    "opt.n_iters = opt.n_epoch * opt.n_iters_1epoch\n",
    "ma_rate = 0.01  # moving average rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_train = True  # set to True to continue to train\n",
    "load_available = False # set to False to prevent loading previous results\n",
    "overwrite = False  # set to True to overwrite previously stored results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GaussianData(opt.sample_size, d=opt.d, rho=opt.rho)\n",
    "X, Y, XY, Ground_truth = data.X, data.Y, torch.cat((data.X, data.Y), dim=1), data.mutual_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GT(x, y):\n",
    "    mi = -0.5 * np.log(1 - opt.rho**2) * opt.d\n",
    "    c = opt.rho / (2 * (1 - opt.rho**2))\n",
    "    return mi + c * (2 * x * y - opt.rho *(x**2 + y**2)).sum(dim=1)\n",
    "\n",
    "\n",
    "def GT_prob(x, y):\n",
    "    \"\"\"\n",
    "    return the probability P(1|X,Y)\n",
    "    \"\"\"\n",
    "    return GT(x, y).exp() / (1+ GT(x, y).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'./results/Smoothed_InfoNCE_GT_dim{opt.d}'   # filename\n",
    "chkpt_name = name+'.pt'      # checkpoint\n",
    "\n",
    "from datetime import datetime\n",
    "TIMESTAMP = \"{0:%Y-%m-%dT%H-%M-%S/}\".format(datetime.now())\n",
    "writer = SummaryWriter(f'./results/log/Smoothed_InfoNCE_GT_dim{opt.d}_reg/{TIMESTAMP}')\n",
    "\n",
    "discriminator = Net(input_size=opt.d*2, hidden_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    discriminator.cuda()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_available and os.path.exists(chkpt_name):\n",
    "    checkpoint = torch.load(\n",
    "        chkpt_name, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mi_list = checkpoint['mi_list']\n",
    "    model_state = checkpoint['model_state']\n",
    "    discriminator.load_state_dict(model_state)\n",
    "    print('Previous results loaded.')\n",
    "else:\n",
    "    mi_list = [] # storing the mi estimation of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subfigure(net, X, Y, dimX, dimY, x0=None, y0=None, xmin=-5, xmax=5, ymin=-5, ymax=5, xgrids=50, ygrids=50, ax=None, show_details=True):\n",
    "    \"\"\"\n",
    "    The inputs should be X and Y, which are the coordinates of the points.\n",
    "\n",
    "    net should be a neural network with Tensor inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    if  x0 == None:\n",
    "        x0 = np.zeros((1, X.shape[1]))\n",
    "    if y0 == None:\n",
    "        y0 = np.zeros((1, Y.shape[1]))\n",
    "        \n",
    "    x, y = np.mgrid[xmin:xmax:xgrids * 1j, ymin:ymax:ygrids * 1j]\n",
    "    with torch.no_grad():\n",
    "        z = (net(\n",
    "            torch.cat((torch.Tensor((np.arange(X.shape[-1]) == dimX).reshape(1, -1) *\n",
    "                    x.reshape(-1, 1) + x0).to(DEVICE),\n",
    "            torch.Tensor((np.arange(X.shape[-1]) == dimY).reshape(1, -1) *\n",
    "                    y.reshape(-1, 1) + y0).to(DEVICE),\n",
    "        ),dim=-1)).reshape(x.shape).cpu())\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    im = ax.pcolormesh(x, y, z, cmap=\"RdBu_r\", shading=\"auto\")\n",
    "    # ax.figure.colorbar(im)\n",
    "    if show_details:\n",
    "        ax.figure.colorbar(im) \n",
    "        ax.set(xlabel=\"$x^{{({0})}}-x_0^{{({0})}}$\",\n",
    "                ylabel=\"$x^{{({0})}}-x_0^{{({0})}}$\",\n",
    "                title=r\"Heatmap of $t(x,y)$\")\n",
    "    return im\n",
    "\n",
    "\n",
    "def plot_fig(net, d=6):\n",
    "    f, axs = plt.subplots(nrows=d,ncols=d,sharex=True, sharey=True)\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            im = plot_subfigure(net, X, Y, dimX=i, dimY=j, x0=None, y0=None, xmin=-5, xmax=5, ymin=-5, ymax=5, xgrids=50, ygrids=50, ax=axs[i, j], show_details=False)\n",
    "    f.colorbar(im, ax=axs.ravel().tolist())\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[1, 2], [3, 4]])\n",
    "b = torch.Tensor([[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tile = a.unsqueeze(0).repeat((a.shape[0], 1, 1))\n",
    "y_tile = b.unsqueeze(1).repeat((1, b.shape[0], 1))\n",
    "train_data = torch.cat([x_tile, y_tile], dim = -1).reshape(-1, a.shape[1]+b.shape[1])\n",
    "train_label = torch.eye(a.shape[0]).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 5., 6.],\n",
       "         [3., 4., 5., 6.],\n",
       "         [1., 2., 7., 8.],\n",
       "         [3., 4., 7., 8.]]),\n",
       " tensor([[3., 4., 5., 6.],\n",
       "         [1., 2., 7., 8.]]),\n",
       " tensor([[1., 2., 5., 6.],\n",
       "         [3., 4., 7., 8.]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_data[train_label==0], train_data[train_label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_loss(net, model, x_data, y_data, writer=None, epoch=None, reg=False):\n",
    "    # alpha: float p(C=0)/p(C=1)\n",
    "    # net: torch.nn.Module\n",
    "    # model: sklearn.tree.DecisionTreeClassifier\n",
    "    # return: loss of smoothed infoNCE\n",
    "    # first term:\n",
    "    # E[f(X,Y)*p(C=1|X,Y)] + alpha*E[f(X',Y')*p(C=1|X',Y')]\n",
    "    joint_samples = torch.cat((x_data, y_data), dim=1)\n",
    "    x_tile = x_data.unsqueeze(0).repeat((x_data.shape[0], 1, 1))\n",
    "    y_tile = y_data.unsqueeze(1).repeat((1, x_data.shape[0], 1))\n",
    "    train_data = torch.cat([x_tile, y_tile], dim = -1).reshape(-1, x_data.shape[1]+y_data.shape[1])\n",
    "    train_label = torch.eye(x_data.shape[0]).reshape(-1,)\n",
    "   \n",
    "    marginal_samples = train_data[train_label==0,:]\n",
    "    prob_DT = model(train_data[:,:opt.d], train_data[:,opt.d:]).reshape(-1,1)\n",
    "    pos_prob_DT = torch.Tensor(prob_DT)[train_label==1,:]\n",
    "    neg_prob_DT = torch.Tensor(prob_DT)[train_label==0,:]\n",
    "    # idx_X = torch.randperm(x_data.shape[0])\n",
    "    # idx_Y = torch.randperm(y_data.shape[0])\n",
    "    # marginal_samples = torch.cat((x_data[idx_X], y_data[idx_Y]), dim=1)\n",
    "    # pos_prob_DT = torch.Tensor(model.predict_proba(joint_samples.cpu().numpy())[:,1].reshape(-1,1))\n",
    "    # neg_prob_DT = torch.Tensor(model.predict_proba(marginal_samples.cpu().numpy())[:,1].reshape(-1,1))\n",
    "    a = (net(joint_samples)*pos_prob_DT).mean() + (net(marginal_samples)*neg_prob_DT).mean()\n",
    "    # second term:\n",
    "    # E[log (E[e^f(X,Y')*p(C=0|X,Y')/p(C=0|X)*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)/p(C=0|X)*p(C=1)|X])]\n",
    "\n",
    "    # b_list contains log (E[e^f(X,Y')*p(C=0|X,Y')/p(C=0|X)*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)/p(C=0|X)*p(C=1)|X]) for each x\n",
    "    b_list = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        x_i = x_data[i,:]\n",
    "        y_i = y_data[i,:]\n",
    "        batch_label = torch.zeros(x_data.shape[0])\n",
    "        batch_label[i] = 1\n",
    "        x_tile = x_i.unsqueeze(0).repeat((x_data.shape[0], 1))\n",
    "        batch_xy = torch.cat([x_tile, y_data], dim = 1)\n",
    "\n",
    "        batch_xy_ = torch.cat((batch_xy[batch_label==1].repeat((batch_xy.shape[0]-1, 1)), batch_xy[batch_label==0]), dim=0)\n",
    "\n",
    "        # P(C=0|x) = E[P(C=0|x,Y')]\n",
    "        pcx = (1-model(batch_xy_[:,:opt.d],batch_xy_[:,opt.d:])).mean()\n",
    "\n",
    "        # b_list.append(torch.log(net(batch_xy[batch_label==1]).exp()* torch.Tensor(model.predict_proba(batch_xy[batch_label==1].cpu().numpy().reshape(1, -1))[:,0])*0.5/pcx + (net(batch_xy[batch_label==0]).exp()*torch.Tensor(model.predict_proba(batch_xy[batch_label==0].cpu().numpy())[:,0].reshape(-1,1))*0.5/pcx).mean()))\n",
    "\n",
    "\n",
    "        b_list.append(torch.logsumexp(net(batch_xy_)+torch.log((1-model(batch_xy_[:,:opt.d],batch_xy_[:,opt.d:])).reshape(-1,1)), dim=0) - np.log(batch_xy_.shape[0]) - torch.log(pcx))\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('a', a, epoch)\n",
    "        writer.add_scalar('b', torch.mean(torch.stack(b_list)), epoch)\n",
    "\n",
    "    if reg:\n",
    "        return a - sum(b_list)/len(b_list) - (sum(b_list)/len(b_list))**2\n",
    "    else:\n",
    "        return a - sum(b_list)/len(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_loss2(net, model, x_data, y_data, writer=None, epoch=None):\n",
    "    # alpha: float p(C=0)/p(C=1)\n",
    "    # net: torch.nn.Module\n",
    "    # model: sklearn.tree.DecisionTreeClassifier\n",
    "    # return: loss of smoothed infoNCE\n",
    "    # first term: \n",
    "    # E[f(X,Y)*p(C=1|X,Y)] + alpha*E[f(X',Y')*p(C=1|X',Y')]\n",
    "    joint_samples = torch.cat((x_data, y_data), dim=1)\n",
    "    x_tile = x_data.unsqueeze(0).repeat((x_data.shape[0], 1, 1))\n",
    "    y_tile = y_data.unsqueeze(1).repeat((1, x_data.shape[0], 1))\n",
    "    train_data = torch.cat([x_tile, y_tile], dim = -1).reshape(-1, x_data.shape[1]+y_data.shape[1])\n",
    "    train_label = torch.eye(x_data.shape[0]).reshape(-1,)\n",
    "   \n",
    "    marginal_samples = train_data[train_label==0,:]\n",
    "    prob_DT = model(train_data[:,:opt.d], train_data[:,opt.d:]).reshape(-1,1)\n",
    "    pos_prob_DT = torch.Tensor(prob_DT)[train_label==1,:]\n",
    "\n",
    "    neg_prob_DT = torch.Tensor(prob_DT)\n",
    "    # idx_X = torch.randperm(x_data.shape[0])\n",
    "    # idx_Y = torch.randperm(y_data.shape[0])\n",
    "    # marginal_samples = torch.cat((x_data[idx_X], y_data[idx_Y]), dim=1)\n",
    "    # pos_prob_DT = torch.Tensor(model.predict_proba(joint_samples.cpu().numpy())[:,1].reshape(-1,1))\n",
    "    # neg_prob_DT = torch.Tensor(model.predict_proba(marginal_samples.cpu().numpy())[:,1].reshape(-1,1))\n",
    "    a = (net(joint_samples)*pos_prob_DT).mean() + (net(train_data)*neg_prob_DT).mean()\n",
    "    # second term:\n",
    "    # E[log (E[e^f(X,Y')*p(C=0|X,Y')/p(C=0|X)*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)/p(C=0|X)*p(C=1)|X])]\n",
    "\n",
    "    # b_list contains log (E[e^f(X,Y')*p(C=0|X,Y')/p(C=0|X)*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)/p(C=0|X)*p(C=1)|X]) for each x\n",
    "    b_list = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        x_i = x_data[i,:]\n",
    "        y_i = y_data[i,:]\n",
    "        batch_label = torch.zeros(x_data.shape[0])\n",
    "        batch_label[i] = 1\n",
    "        x_tile = x_i.unsqueeze(0).repeat((x_data.shape[0], 1))\n",
    "        batch_xy = torch.cat([x_tile, y_data], dim = 1)\n",
    "\n",
    "        batch_xy_ = torch.cat((batch_xy[batch_label==1].repeat((batch_xy.shape[0], 1)), batch_xy), dim=0)\n",
    "\n",
    "        # P(C=0|x) = E[P(C=0|x,Y')]\n",
    "        pcx = (1-model(batch_xy_[:,:opt.d],batch_xy_[:,opt.d:])).mean()\n",
    "\n",
    "        # b_list.append(torch.log(net(batch_xy[batch_label==1]).exp()* torch.Tensor(model.predict_proba(batch_xy[batch_label==1].cpu().numpy().reshape(1, -1))[:,0])*0.5/pcx + (net(batch_xy[batch_label==0]).exp()*torch.Tensor(model.predict_proba(batch_xy[batch_label==0].cpu().numpy())[:,0].reshape(-1,1))*0.5/pcx).mean()))\n",
    "\n",
    "        \n",
    "        b_list.append(torch.logsumexp(net(batch_xy_)+torch.log((1-model(batch_xy_[:,:opt.d],batch_xy_[:,opt.d:])).reshape(-1,1)), dim=0) - np.log(batch_xy_.shape[0]) - torch.log(pcx))\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('a', a, epoch)\n",
    "        writer.add_scalar('b', torch.mean(torch.stack(b_list)), epoch)\n",
    "    return a - sum(b_list)/len(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iternation: 200, loss: -7.139431, mi_est: 6.994064\n"
     ]
    }
   ],
   "source": [
    "# continue_train = False  # set to True to continue to train\n",
    "if continue_train:\n",
    "    _iter = 0\n",
    "    for i in range(opt.n_epoch):\n",
    "        idx = torch.randperm(opt.sample_size)\n",
    "        idx_X, idx_Y = randerange(opt.sample_size)\n",
    "        for j in range(opt.n_iters_1epoch):\n",
    "            batch_idx = idx[j::opt.n_iters_1epoch]\n",
    "            batch_X = X[batch_idx]\n",
    "            batch_Y = Y[batch_idx]\n",
    " \n",
    "            optimizer_D.zero_grad()\n",
    "            loss = - smooth_loss(discriminator, GT_prob, batch_X, batch_Y, reg=True) # negative infonce_bound as the loss\n",
    "            # print(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer_D.step()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mi_est = smooth_loss(discriminator, GT_prob, X, Y, writer, _iter)\n",
    "        mi_list.append(mi_est.item())\n",
    "        writer.add_scalar('mi_list', mi_est.item(), _iter)\n",
    "        writer.add_scalar('loss', loss, _iter)\n",
    "        _iter += 1\n",
    "        if _iter%200==0:\n",
    "            print(\"Iternation: %d, loss: %f, mi_est: %f\"%(_iter, loss.item(), mi_est))\n",
    "            fig = plot_fig(discriminator, opt.d)\n",
    "            writer.add_figure('heatmap', fig, _iter)\n",
    "            writer.add_histogram('first layer', discriminator.fc[0].weight.data, _iter)\n",
    "            writer.add_histogram('second layer', discriminator.fc[1].weight.data, _iter)\n",
    "            writer.add_histogram('third layer', discriminator.fc[2].weight.data, _iter)\n",
    "\n",
    "            writer.add_histogram('first layer (grad)', discriminator.fc[0].weight.grad.data, _iter)\n",
    "            writer.add_histogram('second layer (grad)', discriminator.fc[1].weight.grad.data, _iter)\n",
    "            writer.add_histogram('third layer (grad)', discriminator.fc[2].weight.grad.data, _iter)\n",
    "\n",
    "writer.add_graph(discriminator, (XY,))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mi_list, label='Smoothed InfoNCE')\n",
    "\n",
    "plt.axhline(Ground_truth,label='ground truth',linestyle='--',color='red')\n",
    "plt.axhline(np.log(opt.sample_size),label='log $n$',linestyle='--',color='grey')\n",
    "# for t in range(len(mi_copy)):\n",
    "#     if (mi_copy[t]>.8*Ground_truth):\n",
    "#         plt.axvline(t,label='80% reached',linestyle=':',color='green')\n",
    "#         break\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('MI estimation')\n",
    "plt.title('Mi estimation with Smoothed InfoNCE')\n",
    "plt.legend()\n",
    "plt.savefig(f'results/Smoothed_InfoNCE_dim{opt.d}_ma{ma_rate}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: fc.0.weight grad_requirs: True grad_value: tensor([[-0.0229, -0.0466,  0.0383,  ...,  0.0614, -0.0894,  0.2198],\n",
      "        [-0.0187, -0.0705,  0.0187,  ...,  0.0983, -0.0680,  0.2208],\n",
      "        [-0.0122,  0.0087, -0.0422,  ..., -0.0748,  0.0662, -0.1534],\n",
      "        ...,\n",
      "        [-0.0170,  0.0048, -0.0548,  ..., -0.0825,  0.0259, -0.1222],\n",
      "        [-0.0281, -0.0758, -0.0026,  ...,  0.1041, -0.0782,  0.2238],\n",
      "        [-0.0595, -0.0597,  0.0132,  ...,  0.0880, -0.1293,  0.2469]])\n",
      "name: fc.0.bias grad_requirs: True grad_value: tensor([-0.9224, -0.8778,  0.4744,  0.4234, -0.9043, -1.0166,  0.4298,  0.5655,\n",
      "         0.4693, -1.0354, -0.9200, -0.9050, -0.9638,  0.4456,  0.3871,  0.3872,\n",
      "         0.4935, -0.9590,  0.4722,  0.3059, -0.9603,  0.4551,  0.4682, -1.0840,\n",
      "        -0.9464,  0.4685, -0.8971,  0.4639, -0.9704,  0.4970, -0.9251,  0.4193,\n",
      "         0.3681,  0.5213,  0.4121,  0.4627, -0.9003, -0.9268, -0.9814, -0.8268,\n",
      "         0.5375, -0.9621,  0.4744, -0.8080, -1.0938, -0.9321,  0.4058, -0.8740,\n",
      "        -0.8336, -0.9249, -1.0495,  0.4674, -1.0122,  0.4441, -1.1377,  0.5533,\n",
      "         0.5472, -0.8845, -0.8991, -0.9510, -0.9807, -0.9471,  0.3604,  0.5533,\n",
      "        -1.0055,  0.4443, -0.9737, -0.9827, -1.0317, -0.8949, -0.9390, -0.8576,\n",
      "        -0.9086, -1.0003,  0.4189, -1.0625,  0.4947,  0.4027, -1.0676, -0.9507,\n",
      "        -0.9910,  0.4087,  0.4455, -0.9349, -0.8829, -0.8573, -0.8927, -0.8393,\n",
      "         0.4441,  0.4580, -0.8838, -0.9929,  0.4836,  0.4673, -0.9496,  0.4804,\n",
      "        -1.0614,  0.4334, -0.9532, -1.0504])\n",
      "name: fc.1.weight grad_requirs: True grad_value: tensor([[ 0.0029,  0.0030, -0.0023,  ...,  0.0008,  0.0011,  0.0017],\n",
      "        [-0.0032, -0.0034,  0.0023,  ..., -0.0009, -0.0009, -0.0021],\n",
      "        [ 0.0030,  0.0036, -0.0021,  ...,  0.0009,  0.0011,  0.0018],\n",
      "        ...,\n",
      "        [ 0.0027,  0.0027, -0.0019,  ...,  0.0010,  0.0004,  0.0021],\n",
      "        [-0.0036, -0.0038,  0.0026,  ..., -0.0010, -0.0010, -0.0023],\n",
      "        [ 0.0039,  0.0044, -0.0024,  ...,  0.0009,  0.0007,  0.0027]])\n",
      "name: fc.1.bias grad_requirs: True grad_value: tensor([-0.0467,  0.0495, -0.0450, -0.0452,  0.0539, -0.0466,  0.0504, -0.0422,\n",
      "        -0.0454,  0.0581, -0.0481,  0.0496, -0.0436,  0.0496, -0.0443,  0.0554,\n",
      "        -0.0446,  0.0518, -0.0429, -0.0442, -0.0492, -0.0465, -0.0438,  0.0509,\n",
      "         0.0497, -0.0475, -0.0456, -0.0441,  0.0532, -0.0467,  0.0491,  0.0549,\n",
      "         0.0550,  0.0592, -0.0436, -0.0435, -0.0514,  0.0494,  0.0508, -0.0440,\n",
      "         0.0561,  0.0534,  0.0513,  0.0517, -0.0486,  0.0507,  0.0496,  0.0528,\n",
      "         0.0510,  0.0501,  0.0584,  0.0494,  0.0489,  0.0505,  0.0485, -0.0432,\n",
      "        -0.0439,  0.0500, -0.0440,  0.0485,  0.0515,  0.0500,  0.0483,  0.0579,\n",
      "         0.0527, -0.0459,  0.0521,  0.0558, -0.0434, -0.0459,  0.0490,  0.0562,\n",
      "         0.0513, -0.0455, -0.0453, -0.0480,  0.0512,  0.0525,  0.0510, -0.0482,\n",
      "        -0.0439,  0.0509, -0.0479,  0.0522, -0.0521,  0.0507,  0.0500, -0.0439,\n",
      "         0.0487, -0.0437, -0.0445, -0.0469, -0.0493, -0.0455, -0.0447, -0.0446,\n",
      "         0.0535, -0.0424,  0.0551, -0.0528])\n",
      "name: fc.2.weight grad_requirs: True grad_value: tensor([[-0.0329,  0.0820, -0.0320, -0.0330,  0.0770, -0.0324,  0.0790, -0.0339,\n",
      "         -0.0338,  0.0737, -0.0334,  0.0796, -0.0317,  0.0800, -0.0341,  0.0791,\n",
      "         -0.0361,  0.0784, -0.0329, -0.0313, -0.0310, -0.0337, -0.0320,  0.0813,\n",
      "          0.0800, -0.0347, -0.0354, -0.0326,  0.0811, -0.0325,  0.0784,  0.0784,\n",
      "          0.0777,  0.0744, -0.0344, -0.0309, -0.0307,  0.0792,  0.0779, -0.0334,\n",
      "          0.0759,  0.0768,  0.0793,  0.0803, -0.0323,  0.0798,  0.0809,  0.0788,\n",
      "          0.0791,  0.0800,  0.0759,  0.0780,  0.0802,  0.0779,  0.0814, -0.0353,\n",
      "         -0.0330,  0.0789, -0.0317,  0.0775,  0.0808,  0.0809,  0.0820,  0.0756,\n",
      "          0.0806, -0.0326,  0.0764,  0.0781, -0.0328, -0.0345,  0.0777,  0.0750,\n",
      "          0.0806, -0.0325, -0.0340, -0.0302,  0.0779,  0.0777,  0.0766, -0.0312,\n",
      "         -0.0358,  0.0789, -0.0314,  0.0790, -0.0318,  0.0781,  0.0781, -0.0354,\n",
      "          0.0823, -0.0324, -0.0315, -0.0316, -0.0331, -0.0340, -0.0314, -0.0304,\n",
      "          0.0762, -0.0337,  0.0771, -0.0288]])\n",
      "name: fc.2.bias grad_requirs: True grad_value: tensor([0.1946])\n"
     ]
    }
   ],
   "source": [
    "for name, parms in discriminator.named_parameters():\t\n",
    "    print('name:', name, 'grad_requirs:',parms.requires_grad, \\\n",
    "        'grad_value:',parms.grad)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf1c2c84a0114d8bd094e4ab7df101a23bc9c1c89692267d72e7fbb9a26d536b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
