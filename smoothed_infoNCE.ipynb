{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply label smoothing to infoNCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from src.utils import *\n",
    "from src.mi_estimators import *\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "torch.set_default_tensor_type(FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--rho\", type=float, default=0.9, help=\"coefficient of Gaussian\")\n",
    "parser.add_argument(\"--d\", type=int, default=20, help=\"dimension of X & Y\")\n",
    "parser.add_argument(\"--sample_size\", type=int, default=400, help=\"sample size\")\n",
    "parser.add_argument(\"--gamma\", type=float, default=1e-10, help=\"clipping parameter\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=40, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--hidden_dim\", type=int, default=100, help=\"Hidden dimension\")\n",
    "parser.add_argument(\"--ma_rate\", type=float, default=0.1, help=\"move average rate\")\n",
    "parser.add_argument(\"--ma_ef\", type=float, default=1, help=\"move average ef\")\n",
    "parser.add_argument(\"--alpha\", type=float, default=1e-6, help=\"smooth parameter\")\n",
    "parser.add_argument(\"--reg\", type=int, default=1, help=\"if apply regularization\")\n",
    "parser.add_argument(\"--n_epoch\", type=int, default=2000, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--n_iters_1epoch\", type=int, default=10, help=\"number of epochs of training\")\n",
    "\n",
    "opt, unknown = parser.parse_known_args()\n",
    "opt.n_iters = opt.n_epoch * opt.n_iters_1epoch\n",
    "ma_rate = 0.01  # moving average rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_train = False  # set to True to continue to train\n",
    "load_available = True # set to False to prevent loading previous results\n",
    "overwrite = False  # set to True to overwrite previously stored results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GaussianData(opt.sample_size, d=opt.d, rho=opt.rho)\n",
    "X, Y, XY, Ground_truth = data.X, data.Y, torch.cat((data.X, data.Y), dim=1), data.mutual_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use n*(n-1) samples to train DT\n",
    "# x_tile = X.unsqueeze(0).repeat((opt.sample_size, 1, 1))\n",
    "# y_tile = Y.unsqueeze(1).repeat((1, opt.sample_size, 1))\n",
    "# train_data = torch.cat([x_tile, y_tile], dim = -1).reshape(-1, opt.d*2)\n",
    "# train_label = torch.eye(x_data.shape[0]).reshape(-1,1)\n",
    "\n",
    "# choose n marginal samples to train DT\n",
    "ref_X, ref_Y = shuffle_data(X, Y, opt.sample_size)\n",
    "ref_XY = torch.cat([ref_X, ref_Y], dim = 1)\n",
    "train_data = torch.cat([XY, ref_XY], dim = 0)\n",
    "train_label = torch.cat([torch.ones([opt.sample_size,1]), torch.zeros([opt.sample_size, 1])], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20, min_samples_leaf=20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=20, max_depth=20)\n",
    "# clf = DecisionTreeClassifier(min_samples_leaf=400, max_depth=10)\n",
    "# clf = RandomForestClassifier(n_estimators=10, min_samples_split=5)\n",
    "clf.fit(train_data.cpu().numpy(),  train_label.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = clf.cost_complexity_pruning_path(train_data.cpu().numpy(), train_label.cpu().numpy())\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "# ax.set_xlabel(\"effective alpha\")\n",
    "# ax.set_ylabel(\"total impurity of leaves\")\n",
    "# ax.set_title(\"Total Impurity vs effective alpha for training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0034608214185590236, max_depth=20,\n",
       "                       min_samples_leaf=20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccp = ccp_alphas[round(len(ccp_alphas)/2)]\n",
    "\n",
    "# clf = DecisionTreeClassifier(min_samples_leaf=5, max_depth=8)\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=20, max_depth=20, ccp_alpha=ccp)\n",
    "# clf = RandomForestClassifier(n_estimators=10, min_samples_split=5)\n",
    "clf.fit(train_data.cpu().numpy(),  train_label.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_data.cpu().numpy(),  train_label.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the data needs to train and predict the label\n",
    "x_tile = X.unsqueeze(0).repeat((opt.sample_size, 1, 1))\n",
    "y_tile = Y.unsqueeze(1).repeat((1, opt.sample_size, 1))\n",
    "data_matrix = torch.cat([x_tile, y_tile], dim = -1)\n",
    "DT_prob_matrix = torch.Tensor(clf.predict_proba(data_matrix.reshape(-1, opt.d*2).cpu().numpy())[:,1].reshape(opt.sample_size, opt.sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0705587350896364"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 1e-30\n",
    "DT_prob = clf.predict_proba(XY.cpu().numpy())[:,1]\n",
    "\n",
    "MI_est = np.log(DT_prob / (1 - DT_prob).clip(min=gamma, max=1 - gamma)).mean()\n",
    "# MI_est = np.log(DT_prob / (1 - DT_prob)).mean()\n",
    "\n",
    "MI_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 100\n",
    "# min_, max_ = XY.min().cpu().item(),XY.max().cpu().item()\n",
    "# xx = np.linspace(min_, max_, N)\n",
    "# x1, x2 = np.meshgrid(xx,xx)\n",
    "# pred_ce = model(torch.Tensor([x1.ravel(), x2.ravel()]).T).reshape(x1.shape).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict the point\n",
    "# Z = clf.predict(np.c_[x1.ravel(), x2.ravel()])\n",
    "# Z = Z.reshape(x1.shape)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# # DRAW DECISION BOUNDARY\n",
    "# plt.contourf(x1, x2, Z)\n",
    "# plt.scatter(X[:,0].cpu().numpy(),Y[:,0].cpu().numpy(),label=\"data\",marker=\"+\",color=\"steelblue\")\n",
    "# plt.scatter(ref_X[:,0].cpu().numpy(),ref_Y[:,0].cpu().numpy(),label=\"ref data\",marker=\"+\",color=\"red\")\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# plt.xlim(min_, max_)\n",
    "# plt.ylim(min_, max_)\n",
    "# plt.legend(loc='best')\n",
    "# plt.title('DT decision boundary')\n",
    "# # plt.savefig(f'./results/RF_decision_boundary_{arg.density}_dim{arg.d}_rho{arg.rho}.pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'./results/Smoothed_InfoNCE_dim{opt.d}_reg{opt.reg}_alpha{opt.alpha}'   # filename\n",
    "chkpt_name = name+'.pt'      # checkpoint\n",
    "\n",
    "from datetime import datetime\n",
    "TIMESTAMP = \"{0:%Y-%m-%dT%H-%M-%S/}\".format(datetime.now())\n",
    "writer = SummaryWriter(f'./results/log/Smoothed_InfoNCE_dim{opt.d}_reg{opt.reg}_alpha{opt.alpha}/{TIMESTAMP}')\n",
    "discriminator = Net(input_size=opt.d*2, hidden_layers=2, hidden_size=100)\n",
    "\n",
    "# move NN model to GPU if GPU is available\n",
    "if cuda:\n",
    "    discriminator.cuda()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous results loaded.\n"
     ]
    }
   ],
   "source": [
    "# load_available = True # set to False to prevent loading previous results\n",
    "if load_available and os.path.exists(chkpt_name):\n",
    "    checkpoint = torch.load(\n",
    "        chkpt_name, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mi_list = checkpoint['mi_list']\n",
    "    model_state = checkpoint['model_state']\n",
    "    discriminator.load_state_dict(model_state)\n",
    "    print('Previous results loaded.')\n",
    "else:\n",
    "    mi_list = [] # storing the mi estimation of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def smooth_loss(net, model, x_data, y_data, alpha, writer=None, epoch=None, reg=False):\n",
    "#     # alpha: smoothing factor\n",
    "#     # net: torch.nn.Module\n",
    "#     # model: sklearn.tree.DecisionTreeClassifier\n",
    "#     # return: loss of smoothed infoNCE\n",
    "\n",
    "#     # first term: \n",
    "#     # E[f(X,Y)*p(C=1|X,Y)] + E[f(X',Y')*p(C=1|X',Y')]\n",
    "#     joint_samples = torch.cat((x_data, y_data), dim=1)\n",
    "#     x_tile = x_data.unsqueeze(0).repeat((x_data.shape[0], 1, 1))\n",
    "#     y_tile = y_data.unsqueeze(1).repeat((1, x_data.shape[0], 1))\n",
    "#     train_data = torch.cat([x_tile, y_tile], dim = -1).reshape(-1, x_data.shape[1]+y_data.shape[1])\n",
    "#     train_label = torch.eye(x_data.shape[0]).reshape(-1,)\n",
    "#     # construct the marginal samples\n",
    "#     marginal_samples = train_data[train_label==0,:]\n",
    "#     prob_DT = model.predict_proba(train_data.cpu().numpy())[:,1].reshape(-1,1)\n",
    "#     # smooth the hard labels with the probability of DT\n",
    "#     hard_label = train_label.reshape(-1,1).cpu().numpy()\n",
    "#     prob_DT = alpha*prob_DT + hard_label*(1-alpha)\n",
    "#     pos_prob_DT = torch.Tensor(prob_DT)[train_label==1,:]\n",
    "#     neg_prob_DT = torch.Tensor(prob_DT)[train_label==0,:]\n",
    "\n",
    "#     a = (net(joint_samples)*pos_prob_DT).mean() + (net(marginal_samples)*neg_prob_DT).mean()\n",
    "\n",
    "#     # second term:\n",
    "#     # E[log (E[e^f(X,Y')*p(C=0|X,Y')*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)*p(C=1)|X]) - log p(C=0|X) ] \n",
    "\n",
    "#     # b_list contains log (E[e^f(X,Y')*p(C=0|X,Y')*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)*p(C=1)|X]) - log p(C=0|X) for each x\n",
    "#     b_list = []\n",
    "#     for i in range(x_data.shape[0]):\n",
    "#         x_i = x_data[i,:]\n",
    "#         batch_label = torch.zeros(x_data.shape[0])\n",
    "#         batch_label[i] = 1\n",
    "#         x_tile = x_i.unsqueeze(0).repeat((x_data.shape[0], 1))\n",
    "#         batch_xy = torch.cat([x_tile, y_data], dim = 1)\n",
    "#         # constuct X_tilde Y_tilde by repeating (x_i,y_i) n-1 times and concatenate with all cross samples,\n",
    "#         # therefore there are 2*(n-1) samples in total for a given x_i\n",
    "#         batch_xy_ = torch.cat((batch_xy[batch_label==1,:].repeat((batch_xy.shape[0]-1, 1)), batch_xy[batch_label==0,:]), dim=0)\n",
    "\n",
    "#         # P(C=0|x) = E[P(C=0|x,Y')]\n",
    "#         # pcx is the estimate of p(C=0|x)\n",
    "#         prob_ = model.predict_proba(batch_xy_.cpu().numpy())[:,0].reshape(-1,1)\n",
    "#         # hard_label_ here is the hard label of probability that p(C=0|X,Y)\n",
    "#         hard_label_ = np.concatenate((np.zeros(x_data.shape[0]-1), np.ones(x_data.shape[0]-1))).reshape(-1,1)\n",
    "#         # pcx = (alpha*prob_ + hard_label_*(1-alpha)).mean()\n",
    "#         pcx = 1\n",
    "\n",
    "#         prob_xy_ = alpha*prob_ + hard_label_*(1-alpha)\n",
    "#         b_list.append(torch.logsumexp(net(batch_xy_)+torch.log(torch.Tensor(prob_xy_)), dim=0) - np.log(batch_xy_.shape[0]) - np.log(pcx))\n",
    "\n",
    "#     if writer is not None:\n",
    "#         writer.add_scalar('a', a, epoch)\n",
    "#         writer.add_scalar('b', torch.mean(torch.stack(b_list)), epoch)\n",
    "        \n",
    "#     if reg:\n",
    "#         return a - sum(b_list)/len(b_list) - (sum(b_list)/len(b_list))**2\n",
    "#     else:\n",
    "#         return a - sum(b_list)/len(b_list)\n",
    "\n",
    "def smooth_loss(net, prob_matrix, x_data, y_data, alpha, writer=None, epoch=None, reg=False):\n",
    "    # alpha: smoothing factor\n",
    "    # net: torch.nn.Module\n",
    "    # prob_matrix: the probability estimate matrix of given batch data. size: batchsize * batchsize\n",
    "    # return: loss of smoothed infoNCE\n",
    "\n",
    "    # first term:\n",
    "    # E[f(X,Y)*p(C=1|X,Y)] + E[f(X',Y')*p(C=1|X',Y')]\n",
    "    joint_samples = torch.cat((x_data, y_data), dim=1)\n",
    "    x_tile = x_data.unsqueeze(0).repeat((x_data.shape[0], 1, 1))\n",
    "    y_tile = y_data.unsqueeze(1).repeat((1, x_data.shape[0], 1))\n",
    "    train_data = torch.cat([x_tile, y_tile], dim = -1).reshape(-1, x_data.shape[1]+y_data.shape[1])\n",
    "    train_label = torch.eye(x_data.shape[0]).reshape(-1,)\n",
    "    # construct the marginal samples\n",
    "    marginal_samples = train_data[train_label==0,:]\n",
    "    prob_DT = prob_matrix.reshape(-1, 1)\n",
    "    # smooth the hard labels with the probability of DT\n",
    "    hard_label = train_label.reshape(-1,1)\n",
    "    prob_DT = alpha*prob_DT + hard_label*(1-alpha)\n",
    "    pos_prob_DT = prob_DT[train_label==1,:]\n",
    "    neg_prob_DT = prob_DT[train_label==0,:]\n",
    "\n",
    "    a = (net(joint_samples)*pos_prob_DT).mean() + (net(marginal_samples)*neg_prob_DT).mean()\n",
    "\n",
    "    # second term:\n",
    "    # E[log (E[e^f(X,Y')*p(C=0|X,Y')*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)*p(C=1)|X]) - log p(C=0|X) ]\n",
    "\n",
    "    # b_list contains log (E[e^f(X,Y')*p(C=0|X,Y')*P(C=0)|X] + E[e^f(X,Y)*p(C=0|X,Y)*p(C=1)|X]) - log p(C=0|X) for each x\n",
    "    b_list = []\n",
    "    mask = torch.eye(x_data.shape[0])\n",
    "    for i in range(x_data.shape[0]):\n",
    "        x_i = x_data[i,:]\n",
    "        batch_label = torch.zeros(x_data.shape[0])\n",
    "        batch_label[i] = 1\n",
    "        x_tile = x_i.unsqueeze(0).repeat((x_data.shape[0], 1))\n",
    "        batch_xy = torch.cat([x_tile, y_data], dim = 1)\n",
    "        # constuct X_tilde Y_tilde by repeating (x_i,y_i) n-1 times and concatenate with all cross samples,\n",
    "        # therefore there are 2*(n-1) samples in total for a given x_i\n",
    "        batch_xy_ = torch.cat((batch_xy[batch_label==1,:].repeat((batch_xy.shape[0]-1, 1)), batch_xy[mask[i]==0,:]), dim=0)\n",
    "\n",
    "        # P(C=0|x) = E[P(C=0|x,Y')]\n",
    "        # pcx is the estimate of p(C=0|x)\n",
    "        prob_ = torch.cat((prob_matrix[i, i].repeat(batch_xy.shape[0]-1), prob_matrix[i,mask[i]==0]), dim=0)\n",
    "        # hard_label_ here is the hard label of probability that p(C=0|X,Y)\n",
    "        hard_label_ = torch.cat((torch.zeros(x_data.shape[0]-1), torch.ones(x_data.shape[0]-1))).reshape(-1,1)\n",
    "        # pcx = (alpha*prob_.reshape(-1,1) + hard_label_*(1-alpha)).mean()\n",
    "        prob_xy_ = alpha*prob_.reshape(-1,1) + hard_label_*(1-alpha)\n",
    "        # b_list.append(torch.logsumexp(net(batch_xy_)+torch.log(prob_xy_), dim=0) - np.log(batch_xy_.shape[0]) - torch.log(pcx))\n",
    "        b_list.append(torch.logsumexp(net(batch_xy_)+torch.log(prob_xy_), dim=0) - np.log(batch_xy_.shape[0]))\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('a', a, epoch)\n",
    "        writer.add_scalar('b', torch.mean(torch.stack(b_list)), epoch)\n",
    "\n",
    "    if reg:\n",
    "        return a - sum(b_list)/len(b_list) - (sum(b_list)/len(b_list))**2\n",
    "    else:\n",
    "        return a - sum(b_list)/len(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue_train = False  # set to True to continue to train\n",
    "if continue_train:\n",
    "    _iter = 0\n",
    "    for i in range(opt.n_epoch):\n",
    "        # idx = torch.randperm(opt.sample_size)\n",
    "        idx = np.random.permutation(opt.sample_size)\n",
    "        # idx_X, idx_Y = randerange(opt.sample_size)\n",
    "        for j in range(opt.n_iters_1epoch):\n",
    "            batch_idx = idx[j::opt.n_iters_1epoch]\n",
    "            batch_X = X[batch_idx]\n",
    "            batch_Y = Y[batch_idx]\n",
    "\n",
    "            prob_batch = DT_prob_matrix[np.ix_(batch_idx, batch_idx)]\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "            loss = - smooth_loss(discriminator, prob_batch, batch_X, batch_Y, alpha=opt.alpha, reg=opt.reg) # negative infonce_bound as the loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer_D.step()\n",
    "            with torch.no_grad():\n",
    "                # mi_est = smooth_loss(discriminator, clf, X, Y, alpha=0.2)\n",
    "                mi_est = smooth_loss(discriminator, DT_prob_matrix, X, Y, alpha=opt.alpha)\n",
    "            mi_list.append(mi_est.item())\n",
    "\n",
    "            writer.add_scalar('mi_list', mi_est.item(), _iter)\n",
    "            writer.add_scalar('loss', loss, _iter)\n",
    "        _iter += 1\n",
    "        if _iter%200==0:\n",
    "            print(\"Iternation: %d, loss: %f, mi_est: %f\"%(_iter, loss.item(), mi_est))\n",
    "            fig = plot_fig(discriminator, X, Y, opt.d if opt.d<6 else 6)\n",
    "            writer.add_figure('heatmap', fig, _iter)\n",
    "            writer.add_histogram('first layer', discriminator.fc[0].weight.data, _iter)\n",
    "            writer.add_histogram('second layer', discriminator.fc[1].weight.data, _iter)\n",
    "            writer.add_histogram('third layer', discriminator.fc[2].weight.data, _iter)\n",
    "\n",
    "            writer.add_histogram('first layer (grad)', discriminator.fc[0].weight.grad.data, _iter)\n",
    "            writer.add_histogram('second layer (grad)', discriminator.fc[1].weight.grad.data, _iter)\n",
    "            writer.add_histogram('third layer (grad)', discriminator.fc[2].weight.grad.data, _iter)\n",
    "\n",
    "writer.add_graph(discriminator, (XY,))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current results saved.\n"
     ]
    }
   ],
   "source": [
    "overwrite = True\n",
    "if overwrite or not os.path.exists(chkpt_name):\n",
    "    model_state = discriminator.state_dict()\n",
    "    torch.save({\n",
    "        'mi_list': mi_list,\n",
    "        'model_state': model_state\n",
    "    }, chkpt_name)\n",
    "    writer.close()\n",
    "    print('Current results saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_copy = mi_list.copy()\n",
    "for k in range(1,len(mi_list)):\n",
    "    mi_copy[k] = (1-ma_rate) * mi_copy[k-1] + ma_rate * mi_copy[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1db80be190>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mi_copy, label='Smoothed InfoNCE')\n",
    "\n",
    "plt.axhline(Ground_truth,label='ground truth',linestyle='--',color='red')\n",
    "plt.axhline(np.log(opt.sample_size),label='log $n$',linestyle='--',color='grey')\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('MI estimation')\n",
    "plt.title('MI estimation with Smoothed InfoNCE')\n",
    "plt.legend()\n",
    "# plt.savefig(f'results/InfoNCE_wo_datapoints_dim{opt.d}_ma{ma_rate}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf1c2c84a0114d8bd094e4ab7df101a23bc9c1c89692267d72e7fbb9a26d536b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
